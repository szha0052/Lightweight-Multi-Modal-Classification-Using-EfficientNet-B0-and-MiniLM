{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szha0052/Lightweight-Multi-Modal-Classification-Using-EfficientNet-B0-and-MiniLM/blob/main/COMP5329_A2_All.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fa2c04f",
      "metadata": {
        "id": "6fa2c04f"
      },
      "source": [
        "# COMP5329 Assignment 2 (Group 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064fadf8",
      "metadata": {
        "id": "064fadf8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "%cd /content/drive/MyDrive/COMP5329_A2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fadaeec",
      "metadata": {
        "id": "5fadaeec"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c352412f",
      "metadata": {
        "id": "c352412f",
        "outputId": "86a64636-4af1-4228-adb2-78efa08261d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skmultilearn.model_selection import IterativeStratification\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "from transformers import BertTokenizer\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoConfig\n",
        "\n",
        "import time\n",
        "from skmultilearn.model_selection import IterativeStratification\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import zipfile\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5116a99e",
      "metadata": {
        "id": "5116a99e"
      },
      "source": [
        "## 1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33206bab",
      "metadata": {
        "id": "33206bab"
      },
      "source": [
        "### 1.1 Process the data, remove redundant commas (\",\") in the text, and ensure the data can be successfully read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9195c29b",
      "metadata": {
        "id": "9195c29b"
      },
      "outputs": [],
      "source": [
        "# with zipfile.ZipFile('filename.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d5a1923",
      "metadata": {
        "id": "6d5a1923"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_file = 'COMP5329S1A2Dataset/train.csv'\n",
        "output_file = 'process/train_cleaned.csv'\n",
        "\n",
        "\n",
        "with open(input_file, \"r\", encoding=\"utf-8\") as fin, open(output_file, \"w\", encoding=\"utf-8\") as fout:\n",
        "    for line in fin:\n",
        "        comma1 = line.find(',')\n",
        "        comma2 = line.find(',', comma1+1)\n",
        "        if comma1 == -1 or comma2 == -1:\n",
        "            fout.write(line)\n",
        "            continue\n",
        "\n",
        "        part1 = line[:comma2+1]\n",
        "        part2 = line[comma2+1:]\n",
        "        part2_no_comma = part2.replace(',', '')\n",
        "        fout.write(part1 + part2_no_comma)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3f054dd",
      "metadata": {
        "id": "b3f054dd"
      },
      "source": [
        "### 1.2 Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be30d6b6",
      "metadata": {
        "id": "be30d6b6"
      },
      "outputs": [],
      "source": [
        "\n",
        "image_dir = 'COMP5329S1A2Dataset/data'\n",
        "csv_path = 'process/train_cleaned.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "label_lists = df['Labels'].apply(lambda x: list(map(int, str(x).split())))\n",
        "\n",
        "# Convert labels starting from 1 to start from 0\n",
        "for i in range(len(label_lists)):\n",
        "    label_lists[i] = [x - 1 for x in label_lists[i]]\n",
        "\n",
        "# Count the total number of label categories\n",
        "num_labels = max([max(labels) for labels in label_lists]) + 1\n",
        "mlb = MultiLabelBinarizer(classes=range(num_labels))\n",
        "y_bin = mlb.fit_transform(label_lists)\n",
        "\n",
        "# Convert all text to lowercase\n",
        "df['Caption'] = df['Caption'].str.replace('.', '', regex=False).str.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc873e7c",
      "metadata": {
        "id": "bc873e7c"
      },
      "source": [
        "### 1.3 Stratified Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2feca3a6",
      "metadata": {
        "id": "2feca3a6"
      },
      "outputs": [],
      "source": [
        "# Romdom seed\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Stratified sampling with multiple labels: 80% training set, 20% validation set\n",
        "splitter = IterativeStratification(n_splits=2, order=1)\n",
        "train_idx, val_idx = next(splitter.split(np.zeros(len(df)), y_bin))\n",
        "train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "val_df = df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "# Convert the label columns in train_df and val_df to string format and subtract 1 from all values\n",
        "train_df['Labels'] = train_df['Labels'].apply(lambda x: ' '.join(map(str, [int(i) - 1 for i in str(x).split()])))\n",
        "val_df['Labels'] = val_df['Labels'].apply(lambda x: ' '.join(map(str, [int(i) - 1 for i in str(x).split()])))\n",
        "\n",
        "\n",
        "# Save to CSV\n",
        "train_df.to_csv('process/train_split.csv', index=False)\n",
        "val_df.to_csv('process/val_split.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dda2460",
      "metadata": {
        "id": "6dda2460"
      },
      "source": [
        "## 2. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef481e63",
      "metadata": {
        "id": "ef481e63"
      },
      "source": [
        "### 2.1 Load dataset into DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6b0837e",
      "metadata": {
        "id": "f6b0837e"
      },
      "outputs": [],
      "source": [
        "class MultimodalDataset(Dataset):\n",
        "    def __init__(self, csv_path, image_dir, num_classes=20, max_length=128, is_train=True):\n",
        "        self.data = pd.read_csv(csv_path, quotechar='\"', on_bad_lines='skip')\n",
        "        self.image_dir = image_dir\n",
        "        self.num_classes = num_classes\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.max_length = max_length\n",
        "        self.is_train = is_train\n",
        "\n",
        "        if self.is_train:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((256, 256)),\n",
        "                transforms.RandomResizedCrop(224),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row['ImageID'])\n",
        "        image = self.transform(Image.open(img_path).convert('RGB'))\n",
        "\n",
        "        caption = str(row['Caption'])\n",
        "        text = self.tokenizer(caption, truncation=True, padding='max_length',\n",
        "                              max_length=self.max_length, return_tensors='pt')\n",
        "        input_ids = text['input_ids'].squeeze(0)\n",
        "        attention_mask = text['attention_mask'].squeeze(0)\n",
        "        if self.is_train:\n",
        "            label_indices = list(map(int, str(row['Labels']).split()))\n",
        "            labels = torch.zeros(self.num_classes)\n",
        "            labels[label_indices] = 1.0\n",
        "\n",
        "            return {\n",
        "                'image': image,\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': attention_mask,\n",
        "                'labels': labels\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'image': image,\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': attention_mask\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "877f4e2a",
      "metadata": {
        "id": "877f4e2a"
      },
      "outputs": [],
      "source": [
        "# Load the dataset after layering\n",
        "train_set = MultimodalDataset(csv_path='process/train_split.csv', image_dir=image_dir, num_classes=num_labels, is_train=True)\n",
        "val_set = MultimodalDataset(csv_path='process/val_split.csv', image_dir=image_dir, num_classes=num_labels, is_train=True)\n",
        "\n",
        "# DataLoader Settings\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00aa01a",
      "metadata": {
        "id": "e00aa01a"
      },
      "source": [
        "### 2.2 Define Model Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe88d4af",
      "metadata": {
        "id": "fe88d4af"
      },
      "outputs": [],
      "source": [
        "class MultiModalClassifier(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(MultiModalClassifier, self).__init__()\n",
        "        resnet = models.efficientnet_b0(pretrained=True)\n",
        "        self.image_model = resnet.features\n",
        "        self.image_fc = nn.Linear(1280, 512)\n",
        "\n",
        "        self.text_model = AutoModel.from_pretrained('nreimers/MiniLM-L6-H384-uncased')\n",
        "        self.text_fc = nn.Linear(384, 512)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(512 * 2, num_labels)\n",
        "\n",
        "    def forward(self, image, input_ids, attention_mask):\n",
        "\n",
        "        img_feat = self.image_model(image)\n",
        "\n",
        "\n",
        "        img_feat = nn.functional.adaptive_avg_pool2d(img_feat, 1)\n",
        "        img_feat = img_feat.view(img_feat.size(0), -1)\n",
        "        img_feat = self.image_fc(img_feat)\n",
        "\n",
        "        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_feat = self.text_fc(text_output.last_hidden_state[:, 0, :])\n",
        "\n",
        "        fused = torch.cat((img_feat, text_feat), dim=1)\n",
        "        fused = self.dropout(fused)\n",
        "        out = self.classifier(fused)\n",
        "        return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37541302",
      "metadata": {
        "id": "37541302",
        "outputId": "8135b51e-3925-45bb-a997-4cf9810645cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = MultiModalClassifier(num_labels=num_labels).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d83adfac",
      "metadata": {
        "id": "d83adfac"
      },
      "source": [
        "### 2.3 Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54b8a911",
      "metadata": {
        "id": "54b8a911"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        image = batch['image'].to(device)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(image, input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639e14a3",
      "metadata": {
        "id": "639e14a3"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            image = batch['image'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].cpu().numpy()\n",
        "            outputs = model(image, input_ids, attention_mask).cpu().numpy()\n",
        "            preds.append((outputs > threshold).astype(int))\n",
        "            trues.append(labels)\n",
        "    preds = np.vstack(preds)\n",
        "    trues = np.vstack(trues)\n",
        "    return f1_score(trues, preds, average='micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a0f8267",
      "metadata": {
        "id": "7a0f8267",
        "outputId": "93c06f0e-5674-4577-d46a-212e8fcdc7da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EfficientNet + MiniLM: Epoch 1 - Loss: 0.1802, Train F1: 0.7390, Val F1: 0.7346\n",
            "EfficientNet + MiniLM: Epoch 2 - Loss: 0.1036, Train F1: 0.8141, Val F1: 0.8070\n",
            "EfficientNet + MiniLM: Epoch 3 - Loss: 0.0868, Train F1: 0.8374, Val F1: 0.8224\n",
            "EfficientNet + MiniLM: Epoch 4 - Loss: 0.0794, Train F1: 0.8472, Val F1: 0.8268\n",
            "EfficientNet + MiniLM: Epoch 5 - Loss: 0.0743, Train F1: 0.8578, Val F1: 0.8311\n",
            "EfficientNet + MiniLM: Epoch 6 - Loss: 0.0705, Train F1: 0.8658, Val F1: 0.8310\n",
            "EfficientNet + MiniLM: Epoch 7 - Loss: 0.0665, Train F1: 0.8788, Val F1: 0.8376\n",
            "EfficientNet + MiniLM: Epoch 8 - Loss: 0.0635, Train F1: 0.8871, Val F1: 0.8351\n"
          ]
        }
      ],
      "source": [
        "# Train Model\n",
        "start_time = time.time()\n",
        "for epoch in range(8):\n",
        "    loss = train_loop(model, train_loader, optimizer, criterion, device)\n",
        "    train_f1 = evaluate(model, train_loader, device)\n",
        "    val_f1 = evaluate(model, val_loader, device)\n",
        "    print(f\"EfficientNet + MiniLM: Epoch {epoch+1} - Loss: {loss:.4f}, Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Clear Cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd3de7f",
      "metadata": {
        "id": "1dd3de7f",
        "outputId": "e0d4ae53-8bed-4899-95a7-1099f3886c84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\luo\\AppData\\Local\\Temp\\ipykernel_59164\\2704288716.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  all_models = pd.concat([all_models, new_row], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "# Store Results\n",
        "all_models = pd.DataFrame(columns=['Model_name', 'Loss', 'Train F1', 'Val F1', 'Time'])\n",
        "new_row = pd.DataFrame({\n",
        "    'Model_name': ['EfficientNet + MiniLM'],\n",
        "    'Loss': [loss],\n",
        "    'Train F1': [train_f1],\n",
        "    'Val F1': [val_f1],\n",
        "    'Time': [end_time - start_time]\n",
        "})\n",
        "all_models = pd.concat([all_models, new_row], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f322341d",
      "metadata": {
        "id": "f322341d"
      },
      "source": [
        "### 2.4 Save Model (Quantized Model float32 -> int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0af70897",
      "metadata": {
        "id": "0af70897"
      },
      "outputs": [],
      "source": [
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "\n",
        "torch.save(quantized_model.state_dict(), 'model/quantized_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "273373ab",
      "metadata": {
        "id": "273373ab"
      },
      "source": [
        "## 3. Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccca1b6a",
      "metadata": {
        "id": "ccca1b6a"
      },
      "source": [
        "### 3.1 Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca4c424",
      "metadata": {
        "id": "1ca4c424"
      },
      "outputs": [],
      "source": [
        "class PreMultiModalClassifier(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(PreMultiModalClassifier, self).__init__()\n",
        "        # Load only the efficientnet_b0 framework\n",
        "        resnet = models.efficientnet_b0(pretrained=False)\n",
        "        self.image_model = resnet.features\n",
        "        self.image_fc = nn.Linear(1280, 512)\n",
        "\n",
        "        # Load only the MiniLM framework\n",
        "        config = AutoConfig.from_pretrained(\"nreimers/MiniLM-L6-H384-uncased\")\n",
        "        self.text_model = AutoModel.from_config(config)\n",
        "        self.text_fc = nn.Linear(384, 512)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(512 * 2, num_labels)\n",
        "\n",
        "    def forward(self, image, input_ids, attention_mask):\n",
        "\n",
        "        img_feat = self.image_model(image)\n",
        "\n",
        "\n",
        "        img_feat = nn.functional.adaptive_avg_pool2d(img_feat, 1)\n",
        "        img_feat = img_feat.view(img_feat.size(0), -1)\n",
        "        img_feat = self.image_fc(img_feat)\n",
        "\n",
        "        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_feat = self.text_fc(text_output.last_hidden_state[:, 0, :])\n",
        "\n",
        "        fused = torch.cat((img_feat, text_feat), dim=1)\n",
        "        fused = self.dropout(fused)\n",
        "        out = self.classifier(fused)\n",
        "        return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcf4981b",
      "metadata": {
        "id": "bcf4981b",
        "outputId": "cc639fbb-903c-48b0-aaf3-b05eeb57c281"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torch\\_utils.py:410: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  device=storage.device,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize Model\n",
        "model_test = PreMultiModalClassifier(num_labels=20)\n",
        "\n",
        "# Quantized Model\n",
        "quantized_model_test = torch.quantization.quantize_dynamic(\n",
        "    model_test, {torch.nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "# Load the quantized model state\n",
        "quantized_model_test.load_state_dict(torch.load('model/quantized_model.pth', map_location='cpu'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fdf1a01",
      "metadata": {
        "id": "3fdf1a01"
      },
      "source": [
        "### 3.2 Load test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df1dba2",
      "metadata": {
        "id": "1df1dba2"
      },
      "outputs": [],
      "source": [
        "input_file = 'COMP5329S1A2Dataset/test.csv'\n",
        "output_file = 'process/test_cleaned.csv'\n",
        "with open(input_file, \"r\", encoding=\"utf-8\") as fin, open(output_file, \"w\", encoding=\"utf-8\") as fout:\n",
        "    for line in fin:\n",
        "\n",
        "        comma1 = line.find(',')\n",
        "        if comma1 == -1:\n",
        "            fout.write(line)\n",
        "            continue\n",
        "\n",
        "        part1 = line[:comma1+1]\n",
        "        part2 = line[comma1+1:]\n",
        "        part2_no_comma = part2.replace(',', '')\n",
        "        fout.write(part1 + part2_no_comma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d6f1513",
      "metadata": {
        "id": "3d6f1513"
      },
      "outputs": [],
      "source": [
        "class MultimodalDataset(Dataset):\n",
        "    def __init__(self, csv_path, image_dir, num_classes=20, max_length=128, is_train=True):\n",
        "        self.data = pd.read_csv(csv_path, quotechar='\"', on_bad_lines='skip')\n",
        "        self.image_dir = image_dir\n",
        "        self.num_classes = num_classes\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.max_length = max_length\n",
        "        self.is_train = is_train\n",
        "\n",
        "        if self.is_train:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((256, 256)),\n",
        "                transforms.RandomResizedCrop(224),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row['ImageID'])\n",
        "        image = self.transform(Image.open(img_path).convert('RGB'))\n",
        "\n",
        "        caption = str(row['Caption'])\n",
        "        text = self.tokenizer(caption, truncation=True, padding='max_length',\n",
        "                              max_length=self.max_length, return_tensors='pt')\n",
        "        input_ids = text['input_ids'].squeeze(0)\n",
        "        attention_mask = text['attention_mask'].squeeze(0)\n",
        "        if self.is_train:\n",
        "            label_indices = list(map(int, str(row['Labels']).split()))\n",
        "            labels = torch.zeros(self.num_classes)\n",
        "            labels[label_indices] = 1.0\n",
        "\n",
        "            return {\n",
        "                'image': image,\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': attention_mask,\n",
        "                'labels': labels\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'image': image,\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': attention_mask\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04993cff",
      "metadata": {
        "id": "04993cff"
      },
      "outputs": [],
      "source": [
        "\n",
        "image_dir = 'COMP5329S1A2Dataset/data'\n",
        "\n",
        "# Process the test set\n",
        "test_df = pd.read_csv('process/test_cleaned.csv')\n",
        "test_df['Caption'] = test_df['Caption'].str.replace('.', '', regex=False).str.lower()\n",
        "\n",
        "# Load into DataLoader\n",
        "test_set = MultimodalDataset(csv_path='process/test_cleaned.csv', image_dir=image_dir, num_classes=20, is_train=False)\n",
        "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e4ed64",
      "metadata": {
        "id": "78e4ed64"
      },
      "source": [
        "### 3.3 Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6412f1e3",
      "metadata": {
        "id": "6412f1e3"
      },
      "outputs": [],
      "source": [
        "quantized_model_test.eval()\n",
        "preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        image = batch['image'].to('cpu')\n",
        "        input_ids = batch['input_ids'].to('cpu')\n",
        "        attention_mask = batch['attention_mask'].to('cpu')\n",
        "        outputs = quantized_model_test(image, input_ids, attention_mask).cpu().numpy()\n",
        "        preds.append((outputs > 0.5).astype(int))\n",
        "preds = np.vstack(preds)\n",
        "\n",
        "# Convert prediction results to labels\n",
        "pred_labels = []\n",
        "for pred in preds:\n",
        "    pred_labels.append(' '.join(map(str, np.where(pred == 1)[0] + 1)))  # +1 is because the index starts from 1\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14a35503",
      "metadata": {
        "id": "14a35503"
      },
      "source": [
        "### 3.4 Save Prediction Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350d39a2",
      "metadata": {
        "id": "350d39a2"
      },
      "outputs": [],
      "source": [
        "test_df['PredictedLabels'] = pred_labels\n",
        "pred_df = test_df[['ImageID', 'PredictedLabels']]\n",
        "pred_df.columns = ['ImageID', 'Labels']\n",
        "pred_df.to_csv('Predicted_labels.csv', index=False, header=True, index_label=False)\n",
        "\n",
        "# save to txt file\n",
        "# with open('Predicted_labels.txt', 'w') as f:\n",
        "#     for index, row in pred_df.iterrows():\n",
        "#         f.write(f\"{row['ImageID']},{row['Labels']}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daf7549d",
      "metadata": {
        "id": "daf7549d"
      },
      "source": [
        "## 4. Ablation Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe54e002",
      "metadata": {
        "id": "fe54e002"
      },
      "source": [
        "### 4.1 Only Image Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "373dd1f3",
      "metadata": {
        "id": "373dd1f3"
      },
      "outputs": [],
      "source": [
        "class ImageOnlyClassifier(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(ImageOnlyClassifier, self).__init__()\n",
        "        resnet = models.efficientnet_b0(pretrained=True)\n",
        "        self.image_model = resnet.features\n",
        "        self.image_fc = nn.Linear(1280, 512)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(512, num_labels)\n",
        "\n",
        "    def forward(self, image):\n",
        "        img_feat = self.image_model(image)\n",
        "        img_feat = nn.functional.adaptive_avg_pool2d(img_feat, 1)\n",
        "        img_feat = img_feat.view(img_feat.size(0), -1)\n",
        "        img_feat = self.image_fc(img_feat)\n",
        "        img_feat = self.dropout(img_feat)\n",
        "        out = self.classifier(img_feat)\n",
        "        return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4639ef06",
      "metadata": {
        "id": "4639ef06",
        "outputId": "ea96a261-9928-4fb5-8200-9d0093fa7669"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_image = ImageOnlyClassifier(num_labels=num_labels).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f64d4a8b",
      "metadata": {
        "id": "f64d4a8b"
      },
      "outputs": [],
      "source": [
        "def train_loop_image(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        image = batch['image'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(image)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def evaluate_image(model, dataloader, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            image = batch['image'].to(device)\n",
        "            labels = batch['labels'].cpu().numpy()\n",
        "            outputs = model(image).cpu().numpy()\n",
        "            preds.append((outputs > threshold).astype(int))\n",
        "            trues.append(labels)\n",
        "    preds = np.vstack(preds)\n",
        "    trues = np.vstack(trues)\n",
        "    return f1_score(trues, preds, average='micro')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e54c401",
      "metadata": {
        "id": "2e54c401",
        "outputId": "aadbde54-0e74-4c0e-cfed-32967a16af2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EfficientNet: Epoch 1 - Loss: 0.6938, Train F1: 0.1100, Val F1: 0.1109\n",
            "EfficientNet: Epoch 2 - Loss: 0.6937, Train F1: 0.1074, Val F1: 0.1080\n",
            "EfficientNet: Epoch 3 - Loss: 0.6938, Train F1: 0.1077, Val F1: 0.1082\n",
            "EfficientNet: Epoch 4 - Loss: 0.6938, Train F1: 0.1098, Val F1: 0.1092\n",
            "EfficientNet: Epoch 5 - Loss: 0.6938, Train F1: 0.1048, Val F1: 0.1048\n",
            "EfficientNet: Epoch 6 - Loss: 0.6937, Train F1: 0.1055, Val F1: 0.1066\n",
            "EfficientNet: Epoch 7 - Loss: 0.6938, Train F1: 0.1118, Val F1: 0.1118\n",
            "EfficientNet: Epoch 8 - Loss: 0.6938, Train F1: 0.1042, Val F1: 0.1057\n"
          ]
        }
      ],
      "source": [
        "\n",
        "start_time_image = time.time()\n",
        "for epoch in range(8):\n",
        "    loss_image = train_loop_image(model_image, train_loader, optimizer, criterion, device)\n",
        "    train_f1_image = evaluate_image(model_image, train_loader, device)\n",
        "    val_f1_image = evaluate_image(model_image, val_loader, device)\n",
        "    print(f\"EfficientNet: Epoch {epoch+1} - Loss: {loss_image:.4f}, Train F1: {train_f1_image:.4f}, Val F1: {val_f1_image:.4f}\")\n",
        "end_time_image = time.time()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4803a205",
      "metadata": {
        "id": "4803a205"
      },
      "outputs": [],
      "source": [
        "new_row_image = pd.DataFrame([{'Model_name': 'EfficientNet', 'Loss': loss_image, 'Train F1': train_f1_image, 'Val F1': val_f1_image, 'Time': end_time_image - start_time_image}])\n",
        "all_models =  pd.concat([all_models, new_row_image], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0826aff8",
      "metadata": {
        "id": "0826aff8"
      },
      "source": [
        "### 4.2 Only Text Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc808c6b",
      "metadata": {
        "id": "fc808c6b"
      },
      "outputs": [],
      "source": [
        "class TextOnlyClassifier(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(TextOnlyClassifier, self).__init__()\n",
        "        self.text_model = AutoModel.from_pretrained('nreimers/MiniLM-L6-H384-uncased')\n",
        "        self.text_fc = nn.Linear(384, 512)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(512, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_feat = self.text_fc(text_output.last_hidden_state[:, 0, :])\n",
        "        text_feat = self.dropout(text_feat)\n",
        "        out = self.classifier(text_feat)\n",
        "        return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63650894",
      "metadata": {
        "id": "63650894"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_text = TextOnlyClassifier(num_labels=num_labels).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab4ef33",
      "metadata": {
        "id": "6ab4ef33"
      },
      "outputs": [],
      "source": [
        "def train_loop_text(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def evaluate_text(model, dataloader, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].cpu().numpy()\n",
        "            outputs = model(input_ids, attention_mask).cpu().numpy()\n",
        "            preds.append((outputs > threshold).astype(int))\n",
        "            trues.append(labels)\n",
        "    preds = np.vstack(preds)\n",
        "    trues = np.vstack(trues)\n",
        "    return f1_score(trues, preds, average='micro')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a66894f",
      "metadata": {
        "id": "1a66894f",
        "outputId": "18843a3e-8c0e-48aa-f7d1-ec6eee8834d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MiniL: Epoch 1 - Loss: 0.6748, Train F1: 0.2374, Val F1: 0.2374\n",
            "MiniL: Epoch 2 - Loss: 0.6748, Train F1: 0.2374, Val F1: 0.2374\n",
            "MiniL: Epoch 3 - Loss: 0.6749, Train F1: 0.2374, Val F1: 0.2374\n",
            "MiniL: Epoch 4 - Loss: 0.6748, Train F1: 0.2374, Val F1: 0.2374\n",
            "MiniL: Epoch 5 - Loss: 0.6750, Train F1: 0.2374, Val F1: 0.2374\n",
            "MiniL: Epoch 6 - Loss: 0.6750, Train F1: 0.2374, Val F1: 0.2374\n",
            "MiniL: Epoch 7 - Loss: 0.6750, Train F1: 0.2374, Val F1: 0.2374\n",
            "MiniL: Epoch 8 - Loss: 0.6750, Train F1: 0.2374, Val F1: 0.2374\n"
          ]
        }
      ],
      "source": [
        "start_time_text = time.time()\n",
        "for epoch in range(8):\n",
        "    loss_text = train_loop_text(model_text, train_loader, optimizer, criterion, device)\n",
        "    train_f1_text = evaluate_text(model_text, train_loader, device)\n",
        "    val_f1_text = evaluate_text(model_text, val_loader, device)\n",
        "    print(f\"MiniL: Epoch {epoch+1} - Loss: {loss_text:.4f}, Train F1: {train_f1_text:.4f}, Val F1: {val_f1_text:.4f}\")\n",
        "end_time_text = time.time()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "181dbafa",
      "metadata": {
        "id": "181dbafa"
      },
      "outputs": [],
      "source": [
        "new_row_text = pd.DataFrame([{'Model_name': 'MiniLM', 'Loss': loss_text, 'Train F1': train_f1_text, 'Val F1': val_f1_text, 'Time': end_time_text - start_time_text}])\n",
        "all_models = pd.concat([all_models, new_row_text], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ddee04c",
      "metadata": {
        "id": "8ddee04c"
      },
      "source": [
        "### 4.3 Ablation Experiment Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ffc67b8",
      "metadata": {
        "id": "7ffc67b8"
      },
      "outputs": [],
      "source": [
        "all_models_final = all_models.copy()\n",
        "\n",
        "all_models_final['Train F1'] = all_models_final['Train F1'].apply(lambda x: round(x, 4))\n",
        "all_models_final['Val F1'] = all_models_final['Val F1'].apply(lambda x: round(x, 4))\n",
        "all_models_final['Loss'] = all_models_final['Loss'].apply(lambda x: round(x, 4))\n",
        "\n",
        "all_models_final['Time'] = all_models_final['Time'].apply(lambda x: round(x / 60, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd82b1e",
      "metadata": {
        "id": "1dd82b1e",
        "outputId": "83c7382d-4b7d-447a-866a-5194cdb42e14"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Model_name",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Loss",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Train F1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Val F1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Time",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "28646858-53c1-4639-a60c-1681423bfb7b",
              "rows": [
                [
                  "0",
                  "EfficientNet + MiniLM",
                  "0.0635",
                  "0.8871",
                  "0.8351",
                  "42.5"
                ],
                [
                  "1",
                  "EfficientNet",
                  "0.6938",
                  "0.1042",
                  "0.1057",
                  "39.3"
                ],
                [
                  "2",
                  "MiniLM",
                  "0.675",
                  "0.2374",
                  "0.2374",
                  "37.2"
                ]
              ],
              "shape": {
                "columns": 5,
                "rows": 3
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Train F1</th>\n",
              "      <th>Val F1</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EfficientNet + MiniLM</td>\n",
              "      <td>0.0635</td>\n",
              "      <td>0.8871</td>\n",
              "      <td>0.8351</td>\n",
              "      <td>42.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EfficientNet</td>\n",
              "      <td>0.6938</td>\n",
              "      <td>0.1042</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>39.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MiniLM</td>\n",
              "      <td>0.6750</td>\n",
              "      <td>0.2374</td>\n",
              "      <td>0.2374</td>\n",
              "      <td>37.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Model_name    Loss  Train F1  Val F1  Time\n",
              "0  EfficientNet + MiniLM  0.0635    0.8871  0.8351  42.5\n",
              "1           EfficientNet  0.6938    0.1042  0.1057  39.3\n",
              "2                 MiniLM  0.6750    0.2374  0.2374  37.2"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_models_final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8b2b52",
      "metadata": {
        "id": "dc8b2b52"
      },
      "source": [
        "## 5. Hyperparameter Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40813033",
      "metadata": {
        "id": "40813033"
      },
      "source": [
        "### 5.1 Redefine the model framework to facilitate passing hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406d858b",
      "metadata": {
        "id": "406d858b"
      },
      "outputs": [],
      "source": [
        "class GridMultiModalClassifier(nn.Module):\n",
        "    def __init__(self, num_labels, cell_size=512, dropout_rate=0.3):\n",
        "        super(GridMultiModalClassifier, self).__init__()\n",
        "        resnet = models.efficientnet_b0(pretrained=True)\n",
        "        self.image_model = resnet.features\n",
        "        self.image_fc = nn.Linear(1280, cell_size)  # (batch, 1280)\n",
        "\n",
        "        self.text_model = AutoModel.from_pretrained('nreimers/MiniLM-L6-H384-uncased')\n",
        "        self.text_fc = nn.Linear(384, cell_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(cell_size * 2, num_labels)\n",
        "\n",
        "    def forward(self, image, input_ids, attention_mask):\n",
        "\n",
        "        img_feat = self.image_model(image)\n",
        "        img_feat = nn.functional.adaptive_avg_pool2d(img_feat, 1)\n",
        "        img_feat = img_feat.view(img_feat.size(0), -1)\n",
        "        img_feat = self.image_fc(img_feat)\n",
        "\n",
        "        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_feat = self.text_fc(text_output.last_hidden_state[:, 0, :])\n",
        "\n",
        "        fused = torch.cat((img_feat, text_feat), dim=1)\n",
        "        fused = self.dropout(fused)\n",
        "        out = self.classifier(fused)\n",
        "        return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "503cdcfd",
      "metadata": {
        "id": "503cdcfd"
      },
      "source": [
        "### 5.2 Hyperparameter Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1369e2",
      "metadata": {
        "id": "7f1369e2"
      },
      "outputs": [],
      "source": [
        "# parameter grid\n",
        "param_grid = {\n",
        "    'cell_size': [256, 512, 1024],\n",
        "    'dropout_rate': [0.3, 0.5],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be4c7095",
      "metadata": {
        "id": "be4c7095",
        "outputId": "e25de9c4-526c-4d5e-8ea9-1e6e9004eb89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Training with cell_size=256, dropout_rate=0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid Search: Epoch 1 - Loss: 0.1886, Train F1: 0.7069, Val F1: 0.6980\n",
            "Grid Search: Epoch 2 - Loss: 0.1100, Train F1: 0.8036, Val F1: 0.7960\n",
            "Grid Search: Epoch 3 - Loss: 0.0916, Train F1: 0.8241, Val F1: 0.8117\n",
            "Grid Search: Epoch 4 - Loss: 0.0828, Train F1: 0.8469, Val F1: 0.8272\n",
            "Grid Search: Epoch 5 - Loss: 0.0773, Train F1: 0.8529, Val F1: 0.8286\n",
            "Grid Search: Epoch 6 - Loss: 0.0734, Train F1: 0.8623, Val F1: 0.8279\n",
            "Grid Search: Epoch 7 - Loss: 0.0694, Train F1: 0.8751, Val F1: 0.8357\n",
            "Grid Search: Epoch 8 - Loss: 0.0657, Train F1: 0.8811, Val F1: 0.8347\n",
            "--------------------------------------------------\n",
            "Training with cell_size=256, dropout_rate=0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\luo\\AppData\\Local\\Temp\\ipykernel_16712\\3096061451.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  Grid_results = pd.concat([Grid_results, new_row_grid], ignore_index=True)\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid Search: Epoch 1 - Loss: 0.1988, Train F1: 0.7127, Val F1: 0.7082\n",
            "Grid Search: Epoch 2 - Loss: 0.1158, Train F1: 0.7958, Val F1: 0.7861\n",
            "Grid Search: Epoch 3 - Loss: 0.0960, Train F1: 0.8233, Val F1: 0.8109\n",
            "Grid Search: Epoch 4 - Loss: 0.0871, Train F1: 0.8385, Val F1: 0.8264\n",
            "Grid Search: Epoch 5 - Loss: 0.0813, Train F1: 0.8515, Val F1: 0.8282\n",
            "Grid Search: Epoch 6 - Loss: 0.0765, Train F1: 0.8606, Val F1: 0.8298\n",
            "Grid Search: Epoch 7 - Loss: 0.0728, Train F1: 0.8710, Val F1: 0.8329\n",
            "Grid Search: Epoch 8 - Loss: 0.0693, Train F1: 0.8756, Val F1: 0.8323\n",
            "--------------------------------------------------\n",
            "Training with cell_size=512, dropout_rate=0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid Search: Epoch 1 - Loss: 0.1798, Train F1: 0.7143, Val F1: 0.7087\n",
            "Grid Search: Epoch 2 - Loss: 0.1074, Train F1: 0.8046, Val F1: 0.7957\n",
            "Grid Search: Epoch 3 - Loss: 0.0891, Train F1: 0.8296, Val F1: 0.8176\n",
            "Grid Search: Epoch 4 - Loss: 0.0812, Train F1: 0.8424, Val F1: 0.8241\n",
            "Grid Search: Epoch 5 - Loss: 0.0760, Train F1: 0.8520, Val F1: 0.8285\n",
            "Grid Search: Epoch 6 - Loss: 0.0712, Train F1: 0.8645, Val F1: 0.8329\n",
            "Grid Search: Epoch 7 - Loss: 0.0681, Train F1: 0.8753, Val F1: 0.8355\n",
            "Grid Search: Epoch 8 - Loss: 0.0646, Train F1: 0.8804, Val F1: 0.8359\n",
            "--------------------------------------------------\n",
            "Training with cell_size=512, dropout_rate=0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid Search: Epoch 1 - Loss: 0.1831, Train F1: 0.7249, Val F1: 0.7200\n",
            "Grid Search: Epoch 2 - Loss: 0.1090, Train F1: 0.8108, Val F1: 0.8014\n",
            "Grid Search: Epoch 3 - Loss: 0.0915, Train F1: 0.8287, Val F1: 0.8176\n",
            "Grid Search: Epoch 4 - Loss: 0.0831, Train F1: 0.8451, Val F1: 0.8245\n",
            "Grid Search: Epoch 5 - Loss: 0.0777, Train F1: 0.8548, Val F1: 0.8297\n",
            "Grid Search: Epoch 6 - Loss: 0.0737, Train F1: 0.8628, Val F1: 0.8332\n",
            "Grid Search: Epoch 7 - Loss: 0.0701, Train F1: 0.8706, Val F1: 0.8343\n",
            "Grid Search: Epoch 8 - Loss: 0.0666, Train F1: 0.8777, Val F1: 0.8300\n",
            "--------------------------------------------------\n",
            "Training with cell_size=1024, dropout_rate=0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid Search: Epoch 1 - Loss: 0.1690, Train F1: 0.7453, Val F1: 0.7401\n",
            "Grid Search: Epoch 2 - Loss: 0.1007, Train F1: 0.8139, Val F1: 0.8056\n",
            "Grid Search: Epoch 3 - Loss: 0.0856, Train F1: 0.8352, Val F1: 0.8210\n",
            "Grid Search: Epoch 4 - Loss: 0.0782, Train F1: 0.8502, Val F1: 0.8292\n",
            "Grid Search: Epoch 5 - Loss: 0.0735, Train F1: 0.8599, Val F1: 0.8360\n",
            "Grid Search: Epoch 6 - Loss: 0.0693, Train F1: 0.8745, Val F1: 0.8367\n",
            "Grid Search: Epoch 7 - Loss: 0.0657, Train F1: 0.8763, Val F1: 0.8310\n",
            "Grid Search: Epoch 8 - Loss: 0.0624, Train F1: 0.8851, Val F1: 0.8336\n",
            "--------------------------------------------------\n",
            "Training with cell_size=1024, dropout_rate=0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid Search: Epoch 1 - Loss: 0.1726, Train F1: 0.7150, Val F1: 0.7090\n",
            "Grid Search: Epoch 2 - Loss: 0.1048, Train F1: 0.8064, Val F1: 0.7983\n",
            "Grid Search: Epoch 3 - Loss: 0.0878, Train F1: 0.8302, Val F1: 0.8142\n",
            "Grid Search: Epoch 4 - Loss: 0.0805, Train F1: 0.8481, Val F1: 0.8293\n",
            "Grid Search: Epoch 5 - Loss: 0.0751, Train F1: 0.8599, Val F1: 0.8308\n",
            "Grid Search: Epoch 6 - Loss: 0.0709, Train F1: 0.8660, Val F1: 0.8371\n",
            "Grid Search: Epoch 7 - Loss: 0.0676, Train F1: 0.8753, Val F1: 0.8357\n",
            "Grid Search: Epoch 8 - Loss: 0.0643, Train F1: 0.8796, Val F1: 0.8326\n"
          ]
        }
      ],
      "source": [
        "Grid_results = pd.DataFrame(columns=['Cell_size', 'Dropout_rate', 'Loss', 'Train F1', 'Val F1', 'Time'])\n",
        "\n",
        "for cell_size in param_grid['cell_size']:\n",
        "    for dropout_rate in param_grid['dropout_rate']:\n",
        "        print('-' * 50)\n",
        "        print(f\"Training with cell_size={cell_size}, dropout_rate={dropout_rate}\")\n",
        "        model = GridMultiModalClassifier(num_labels=num_labels, cell_size=cell_size, dropout_rate=dropout_rate).to(device)\n",
        "        optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        start_time_grid = time.time()\n",
        "        for epoch in range(8):\n",
        "            loss_grid = train_loop(model, train_loader, optimizer, criterion, device)\n",
        "            train_f1_grid = evaluate(model, train_loader, device)\n",
        "            val_f1_grid = evaluate(model, val_loader, device)\n",
        "            print(f\"Grid Search: Epoch {epoch+1} - Loss: {loss_grid:.4f}, Train F1: {train_f1_grid:.4f}, Val F1: {val_f1_grid:.4f}\")\n",
        "        end_time_grid = time.time()\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        new_row_grid = pd.DataFrame([{'Cell_size': cell_size, 'Dropout_rate': dropout_rate, 'Loss': loss_grid, 'Train F1': train_f1_grid, 'Val F1': val_f1_grid, 'Time': end_time_grid - start_time_grid}])\n",
        "        Grid_results = pd.concat([Grid_results, new_row_grid], ignore_index=True)\n",
        "\n",
        "Grid_results_final = Grid_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b831cca",
      "metadata": {
        "id": "7b831cca"
      },
      "source": [
        "### 5.3 Hyperparameter Selection Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f35bcf9",
      "metadata": {
        "id": "3f35bcf9",
        "outputId": "009485b2-9647-48c5-8e8e-3875373b93e2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Cell_size",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "Dropout_rate",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Loss",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Train F1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Val F1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Time",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "0a87a003-c58a-4186-8bd0-1a6a2ea4ccc5",
              "rows": [
                [
                  "0",
                  "256",
                  "0.3",
                  "0.0657",
                  "0.8811",
                  "0.8347",
                  "42.4"
                ],
                [
                  "1",
                  "256",
                  "0.5",
                  "0.0693",
                  "0.8756",
                  "0.8323",
                  "42.4"
                ],
                [
                  "2",
                  "512",
                  "0.3",
                  "0.0646",
                  "0.8804",
                  "0.8359",
                  "42.4"
                ],
                [
                  "3",
                  "512",
                  "0.5",
                  "0.0666",
                  "0.8777",
                  "0.83",
                  "42.5"
                ],
                [
                  "4",
                  "1024",
                  "0.3",
                  "0.0624",
                  "0.8851",
                  "0.8336",
                  "42.4"
                ],
                [
                  "5",
                  "1024",
                  "0.5",
                  "0.0643",
                  "0.8796",
                  "0.8326",
                  "42.3"
                ]
              ],
              "shape": {
                "columns": 6,
                "rows": 6
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cell_size</th>\n",
              "      <th>Dropout_rate</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Train F1</th>\n",
              "      <th>Val F1</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>256</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0657</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>0.8347</td>\n",
              "      <td>42.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>256</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.8756</td>\n",
              "      <td>0.8323</td>\n",
              "      <td>42.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>512</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0646</td>\n",
              "      <td>0.8804</td>\n",
              "      <td>0.8359</td>\n",
              "      <td>42.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>512</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.8777</td>\n",
              "      <td>0.8300</td>\n",
              "      <td>42.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1024</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0624</td>\n",
              "      <td>0.8851</td>\n",
              "      <td>0.8336</td>\n",
              "      <td>42.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1024</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0643</td>\n",
              "      <td>0.8796</td>\n",
              "      <td>0.8326</td>\n",
              "      <td>42.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Cell_size  Dropout_rate    Loss  Train F1  Val F1  Time\n",
              "0       256           0.3  0.0657    0.8811  0.8347  42.4\n",
              "1       256           0.5  0.0693    0.8756  0.8323  42.4\n",
              "2       512           0.3  0.0646    0.8804  0.8359  42.4\n",
              "3       512           0.5  0.0666    0.8777  0.8300  42.5\n",
              "4      1024           0.3  0.0624    0.8851  0.8336  42.4\n",
              "5      1024           0.5  0.0643    0.8796  0.8326  42.3"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Grid_results_final['Train F1'] = Grid_results_final['Train F1'].apply(lambda x: round(x, 4))\n",
        "Grid_results_final['Val F1'] = Grid_results_final['Val F1'].apply(lambda x: round(x, 4))\n",
        "Grid_results_final['Loss'] = Grid_results_final['Loss'].apply(lambda x: round(x, 4))\n",
        "Grid_results_final['Time'] = Grid_results_final['Time'].apply(lambda x: round(x / 60, 1))\n",
        "Grid_results_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47670bd2",
      "metadata": {
        "id": "47670bd2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "CXXA1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}