{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa2c04f",
   "metadata": {},
   "source": [
    "# COMP5329 Assignment 2 (Group 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "%cd /content/drive/MyDrive/COMP5329_A2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c352412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from transformers import BertTokenizer\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoConfig\n",
    "import zipfile\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273373ab",
   "metadata": {},
   "source": [
    "## 1. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccca1b6a",
   "metadata": {},
   "source": [
    "### 1.1 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca4c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreMultiModalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(PreMultiModalClassifier, self).__init__()\n",
    "        # Load only the efficientnet_b0 framework\n",
    "        resnet = models.efficientnet_b0(pretrained=False)\n",
    "        self.image_model = resnet.features\n",
    "        self.image_fc = nn.Linear(1280, 512)  \n",
    "\n",
    "        # Load only the MiniLM framework\n",
    "        config = AutoConfig.from_pretrained(\"nreimers/MiniLM-L6-H384-uncased\")\n",
    "        self.text_model = AutoModel.from_config(config)\n",
    "        self.text_fc = nn.Linear(384, 512)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(512 * 2, num_labels)\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "\n",
    "        img_feat = self.image_model(image) \n",
    "\n",
    "\n",
    "        img_feat = nn.functional.adaptive_avg_pool2d(img_feat, 1)\n",
    "        img_feat = img_feat.view(img_feat.size(0), -1) \n",
    "        img_feat = self.image_fc(img_feat)\n",
    "\n",
    "        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_feat = self.text_fc(text_output.last_hidden_state[:, 0, :])\n",
    "\n",
    "        fused = torch.cat((img_feat, text_feat), dim=1)\n",
    "        fused = self.dropout(fused)\n",
    "        out = self.classifier(fused)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf4981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "d:\\EnvOfCode\\anaconda3\\envs\\CXXA1\\lib\\site-packages\\torch\\_utils.py:410: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Model\n",
    "model_test = PreMultiModalClassifier(num_labels=20)\n",
    "\n",
    "# Quantized Model\n",
    "quantized_model_test = torch.quantization.quantize_dynamic(\n",
    "    model_test, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "# Load the quantized model state\n",
    "quantized_model_test.load_state_dict(torch.load('model/quantized_model.pth', map_location='cpu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf1a01",
   "metadata": {},
   "source": [
    "### 3.2 Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9cd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile('filename.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df1dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'COMP5329S1A2Dataset/test.csv'\n",
    "output_file = 'process/test_cleaned.csv'\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as fin, open(output_file, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for line in fin:\n",
    "\n",
    "        comma1 = line.find(',')\n",
    "        if comma1 == -1:\n",
    "            fout.write(line)\n",
    "            continue\n",
    "\n",
    "        part1 = line[:comma1+1] \n",
    "        part2 = line[comma1+1:] \n",
    "        part2_no_comma = part2.replace(',', '') \n",
    "        fout.write(part1 + part2_no_comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d6f1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, csv_path, image_dir, num_classes=20, max_length=128, is_train=True):\n",
    "        self.data = pd.read_csv(csv_path, quotechar='\"', on_bad_lines='skip')\n",
    "        self.image_dir = image_dir\n",
    "        self.num_classes = num_classes\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.max_length = max_length\n",
    "        self.is_train = is_train\n",
    "\n",
    "        if self.is_train:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['ImageID'])\n",
    "        image = self.transform(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "        caption = str(row['Caption'])\n",
    "        text = self.tokenizer(caption, truncation=True, padding='max_length',\n",
    "                              max_length=self.max_length, return_tensors='pt')\n",
    "        input_ids = text['input_ids'].squeeze(0)\n",
    "        attention_mask = text['attention_mask'].squeeze(0)\n",
    "        if self.is_train:\n",
    "            label_indices = list(map(int, str(row['Labels']).split()))\n",
    "            labels = torch.zeros(self.num_classes)\n",
    "            labels[label_indices] = 1.0\n",
    "\n",
    "            return {\n",
    "                'image': image,\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'labels': labels\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'image': image,\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04993cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dir = 'COMP5329S1A2Dataset/data'\n",
    "\n",
    "# Process the test set\n",
    "test_df = pd.read_csv('process/test_cleaned.csv')\n",
    "test_df['Caption'] = test_df['Caption'].str.replace('.', '', regex=False).str.lower()\n",
    "\n",
    "# Load into DataLoader\n",
    "test_set = MultimodalDataset(csv_path='process/test_cleaned.csv', image_dir=image_dir, num_classes=20, is_train=False)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e4ed64",
   "metadata": {},
   "source": [
    "### 3.3 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6412f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model_test.eval()\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        image = batch['image'].to('cpu')\n",
    "        input_ids = batch['input_ids'].to('cpu')\n",
    "        attention_mask = batch['attention_mask'].to('cpu')\n",
    "        outputs = quantized_model_test(image, input_ids, attention_mask).cpu().numpy()\n",
    "        preds.append((outputs > 0.5).astype(int))\n",
    "preds = np.vstack(preds)\n",
    "\n",
    "# Convert prediction results to labels\n",
    "pred_labels = []\n",
    "for pred in preds:\n",
    "    pred_labels.append(' '.join(map(str, np.where(pred == 1)[0] + 1)))  # +1 is because the index starts from 1\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a35503",
   "metadata": {},
   "source": [
    "### 3.4 Save Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "350d39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['PredictedLabels'] = pred_labels\n",
    "pred_df = test_df[['ImageID', 'PredictedLabels']]\n",
    "pred_df.columns = ['ImageID', 'Labels']\n",
    "pred_df.to_csv('Predicted_labels.csv', index=False, header=True, index_label=False)\n",
    "\n",
    "# save to txt file\n",
    "# with open('Predicted_labels.txt', 'w') as f:\n",
    "#     for index, row in pred_df.iterrows():\n",
    "#         f.write(f\"{row['ImageID']},{row['Labels']}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CXXA1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
